{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7be7d6",
   "metadata": {},
   "source": [
    "# STA130 Project Tutorial Assignment 1\n",
    "**Group member**:\n",
    "- Vu My Hanh Tran\n",
    "- Zhaoyang Wang\n",
    "- Cheryl Tong\n",
    "- Jiawei Gao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23449fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>transformer_probability_prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.183897</td>\n",
       "      <td>0.183897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.267831</td>\n",
       "      <td>0.267831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.482585</td>\n",
       "      <td>0.482585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.187792</td>\n",
       "      <td>0.187792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.539319</td>\n",
       "      <td>0.460681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>False</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>0.182196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>False</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>0.203236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>False</td>\n",
       "      <td>0.527107</td>\n",
       "      <td>0.527107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>False</td>\n",
       "      <td>0.555677</td>\n",
       "      <td>0.555677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>True</td>\n",
       "      <td>0.565700</td>\n",
       "      <td>0.434300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true_transformer  y_pred_proba_transformer  \\\n",
       "0                 False                  0.183897   \n",
       "1                 False                  0.267831   \n",
       "2                 False                  0.482585   \n",
       "3                 False                  0.187792   \n",
       "4                  True                  0.539319   \n",
       "..                  ...                       ...   \n",
       "359               False                  0.182196   \n",
       "360               False                  0.203236   \n",
       "361               False                  0.527107   \n",
       "362               False                  0.555677   \n",
       "363                True                  0.565700   \n",
       "\n",
       "     transformer_probability_prediction_error  \n",
       "0                                    0.183897  \n",
       "1                                    0.267831  \n",
       "2                                    0.482585  \n",
       "3                                    0.187792  \n",
       "4                                    0.460681  \n",
       "..                                        ...  \n",
       "359                                  0.182196  \n",
       "360                                  0.203236  \n",
       "361                                  0.527107  \n",
       "362                                  0.555677  \n",
       "363                                  0.434300  \n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "\n",
    "df_preds = pd.read_csv('test_predictions.csv')\n",
    "# Prediction Probility \"Error\"\n",
    "\n",
    "# using transformer for this example demonstration, as opposed to\n",
    "# df_preds.y_true_ffnn and df_preds.y_pred_proba_ffnn\n",
    "# df_preds.y_true_xgboost and df_preds.y_pred_proba_xgboost\n",
    "\n",
    "# quick and dirty scalars to represent prediction 'wrongness'\n",
    "# (subtract model's prediction probability from boolean true value)\n",
    "df_preds['transformer_probability_prediction_error'] = np.abs(df_preds['y_true_transformer'].astype(float) - df_preds['y_pred_proba_transformer'])\n",
    "df_preds[['y_true_transformer','y_pred_proba_transformer','transformer_probability_prediction_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e63f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_transformer  y_pred_transformer  \\\n",
       "30                True                True   \n",
       "31               False                True   \n",
       "32               False                True   \n",
       "33               False                True   \n",
       "34               False               False   \n",
       "35               False                True   \n",
       "36               False               False   \n",
       "37               False               False   \n",
       "38               False                True   \n",
       "39               False                True   \n",
       "40               False                True   \n",
       "41               False                True   \n",
       "42               False                True   \n",
       "43               False               False   \n",
       "44               False               False   \n",
       "45               False               False   \n",
       "46               False               False   \n",
       "47                True               False   \n",
       "48               False               False   \n",
       "49               False               False   \n",
       "\n",
       "   transformer_classifcation_performance_outcome  \n",
       "30                correctly predicted escalation  \n",
       "31                  wrongly predicted escalation  \n",
       "32                  wrongly predicted escalation  \n",
       "33                  wrongly predicted escalation  \n",
       "34             correctly predicted no escalation  \n",
       "35                  wrongly predicted escalation  \n",
       "36             correctly predicted no escalation  \n",
       "37             correctly predicted no escalation  \n",
       "38                  wrongly predicted escalation  \n",
       "39                  wrongly predicted escalation  \n",
       "40                  wrongly predicted escalation  \n",
       "41                  wrongly predicted escalation  \n",
       "42                  wrongly predicted escalation  \n",
       "43             correctly predicted no escalation  \n",
       "44             correctly predicted no escalation  \n",
       "45             correctly predicted no escalation  \n",
       "46             correctly predicted no escalation  \n",
       "47               wrongly predicted no escalation  \n",
       "48             correctly predicted no escalation  \n",
       "49             correctly predicted no escalation  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Classification \"Correctness\"\n",
    "\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "# using transformer for this example demonstration, as opposed to\n",
    "# df_preds.y_true_ffnn and df_preds.y_pred_proba_ffnn>threshold\n",
    "# df_preds.y_true_xgboost and df_preds.y_pred_proba_xgboost>threshold\n",
    "df_preds['transformer_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_preds['transformer_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['transformer_classifcation_performance_outcome'] = tmp\n",
    "df_preds[['y_true_transformer','y_pred_transformer','transformer_classifcation_performance_outcome']][30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c8e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# arbitrary simulation parameters\n",
    "n,R = 5,100\n",
    "\n",
    "# a first \"sample\"\n",
    "sample_1 = np.arange(n)\n",
    "\n",
    "# bootstrapping a single sample\n",
    "for rep in range(R):\n",
    "    bootstrap_sample = np.random.choice(sample_1, size=n)\n",
    "    # original sample size maintained, of course; and, this function defaults to `replace=True`...\n",
    "\n",
    "# coin flipping under a specified null hypothesis\n",
    "for rep in range(R):\n",
    "    binary_sample = np.random.choice([0,1], p=[0.5,0.5], size=n)\n",
    "\n",
    "# a second \"sample\"\n",
    "sample_2 = np.arange(n,2*n)\n",
    "\n",
    "# bootstrapping two samples separately\n",
    "for rep in range(R):\n",
    "    bootstrap_sample_1 = np.random.choice(sample_1, size=n)\n",
    "    bootstrap_sample_2 = np.random.choice(sample_2, size=n)\n",
    "    \n",
    "# permutation/shuffling of \"treatment/group\" labels\n",
    "# corresponds to a null hypothesis that the \"treatment/group\" labels don't matter\n",
    "labels = np.array([\"sample_1\"]*n + [\"sample_2\"]*n)\n",
    "all_samples = np.concatenate([sample_1, sample_2], axis=0)\n",
    "for rep in range(R):\n",
    "    # `replace=False` is very important\n",
    "    shuffled_samples = np.random.choice(all_samples, size=n*2, replace=False)\n",
    "    # keeping the same original sample sizes is very important (as they could be different...)\n",
    "    shuffled_sample_1 = shuffled_samples[labels==\"sample_1\"]#[:n]\n",
    "    shuffled_sample_2 = shuffled_samples[labels==\"sample_2\"]#[n:]\n",
    "\n",
    "# \"paired\" samples analysis\n",
    "sample_difference = sample_1 - sample_2\n",
    "\n",
    "# bootstrapping a \"paired\" sample\n",
    "for rep in range(R):\n",
    "    bootstrap_sample = np.random.choice(sample_difference, size=n)\n",
    "\n",
    "# null hypothesis of \"order doesn't matter\" for a \"paired\" sample\n",
    "for rep in range(R):\n",
    "    order_of_subtraction = np.random.choice([1,-1], p=[0.5,0.5], size=n)\n",
    "    sample_difference_random_order = sample_difference*order_of_subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c6e70",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438c1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prediction probability error for xgboost\n",
    "df_preds['xgboost_probability_prediction_error'] = np.abs(df_preds['y_true_xgboost'].astype(float) - df_preds['y_pred_proba_xgboost'])\n",
    "\n",
    "# Calculate prediction probability error for ffnn\n",
    "df_preds['ffnn_probability_prediction_error'] = np.abs(df_preds['y_true_ffnn'].astype(float) - df_preds['y_pred_proba_ffnn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e57a557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.066500\n",
       "1      0.099643\n",
       "2      0.295914\n",
       "3      0.361556\n",
       "4      0.608380\n",
       "         ...   \n",
       "359    0.079453\n",
       "360    0.060189\n",
       "361    0.302375\n",
       "362    0.729246\n",
       "363    0.591722\n",
       "Name: xgboost_probability_prediction_error, Length: 364, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds['xgboost_probability_prediction_error'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda3195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.409958\n",
       "1      0.406696\n",
       "2      0.545236\n",
       "3      0.534560\n",
       "4      0.461417\n",
       "         ...   \n",
       "359    0.291874\n",
       "360    0.300321\n",
       "361    0.335496\n",
       "362    0.324000\n",
       "363    0.667545\n",
       "Name: ffnn_probability_prediction_error, Length: 364, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds['ffnn_probability_prediction_error'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce3027",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ddbc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xgboost'\n",
    "\n",
    "# Extract the prediction probability error values for the chosen model\n",
    "prediction_error = df_preds[f'{model_name}_probability_prediction_error'].values\n",
    "\n",
    "# Set the number of bootstrap samples\n",
    "n_bootstrap = 1000\n",
    "\n",
    "# Initialize an array to store the bootstrap sample means\n",
    "bootstrap_sample_means = np.zeros(n_bootstrap)\n",
    "\n",
    "# Perform bootstrap resampling\n",
    "for i in range(n_bootstrap):\n",
    "    # Generate a bootstrap sample by sampling with replacement\n",
    "    bootstrap_sample = np.random.choice(prediction_error, size=len(prediction_error), replace=True)\n",
    "    \n",
    "    # Calculate the mean of the bootstrap sample\n",
    "    bootstrap_sample_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "# Calculate the lower and upper percentiles of the bootstrap sample means\n",
    "lower_percentile = np.percentile(bootstrap_sample_means, 2.5)\n",
    "lower_percentile = np.percentile(bootstrap_sample_means, 97.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebcf1e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.469922000057335, 0.469922000057335)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lower_percentile, lower_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c976414",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "485c09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Prediction Classification \"Correctness\" results for transformer\n",
    "df_preds['transformer_correctness'] = np.where(df_preds['y_true_transformer'] == df_preds['y_pred_transformer'], 'correct', 'incorrect')\n",
    "\n",
    "# Create Prediction Classification \"Correctness\" results for xgboost\n",
    "df_preds['xgboost_correctness'] = np.where(df_preds['y_true_xgboost'] == df_preds['y_pred_xgboost'], 'correct', 'incorrect')\n",
    "\n",
    "# Create Prediction Classification \"Correctness\" results for ffnn\n",
    "df_preds['ffnn_correctness'] = np.where(df_preds['y_true_ffnn'] == df_preds['y_pred_ffnn'], 'correct', 'incorrect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac4be02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        correct\n",
       "1        correct\n",
       "2        correct\n",
       "3        correct\n",
       "4        correct\n",
       "         ...    \n",
       "359      correct\n",
       "360      correct\n",
       "361    incorrect\n",
       "362    incorrect\n",
       "363      correct\n",
       "Name: transformer_correctness, Length: 364, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds['transformer_correctness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36fa93f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        correct\n",
       "1        correct\n",
       "2        correct\n",
       "3        correct\n",
       "4      incorrect\n",
       "         ...    \n",
       "359      correct\n",
       "360      correct\n",
       "361      correct\n",
       "362    incorrect\n",
       "363    incorrect\n",
       "Name: xgboost_correctness, Length: 364, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds['xgboost_correctness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69df7081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        correct\n",
       "1        correct\n",
       "2      incorrect\n",
       "3      incorrect\n",
       "4        correct\n",
       "         ...    \n",
       "359      correct\n",
       "360      correct\n",
       "361      correct\n",
       "362      correct\n",
       "363    incorrect\n",
       "Name: ffnn_correctness, Length: 364, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds['ffnn_correctness']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10dd33e",
   "metadata": {},
   "source": [
    "# Questions 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0237a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binomtest\n",
    "\n",
    "# Select the model for which to perform the hypothesis test\n",
    "selected_model = 'xgboost'\n",
    "\n",
    "# Determine the null hypothesis\n",
    "null_proportion = 0.4\n",
    "\n",
    "# Extract the Prediction Classification \"Correctness\" results for the selected model\n",
    "correctness = df_preds[f'{selected_model}_correctness']\n",
    "\n",
    "# Calculate the proportion of the specific Prediction Classification \"Correctness\" category\n",
    "proportion = correctness.value_counts(normalize=True)['incorrect']\n",
    "\n",
    "# Perform the hypothesis test using the binomtest function\n",
    "p_value = binomtest(int(proportion * len(correctness)), n=len(correctness), p=null_proportion).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d75c574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002681471561002832"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79926d9",
   "metadata": {},
   "source": [
    "> The calculated p-value for the one-sample hypothesis test is approximately 0.0003. Based on this result, we have very strong evidence to reject the null hypothesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
